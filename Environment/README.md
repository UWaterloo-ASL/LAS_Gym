# Environment class
This folder contains **Environment** classes which are a layer of interface between Learning Agent and Simulated Environment in V-REP. All sensory data will be sent to learning agent from these interface classes, while all action command generated by learning agent will be sent to actuators in V-REP through these interface classes too.

The public interface functions in these classes follow convention of [the Env class in OpenAi Gym](https://gym.openai.com/docs/), which includes:

  1. `observation = env.reset()`
  2. `observation, rewward, done, info = env.step(action)`

## Step 1. Run the Simulating Scene in V-REP
#### Method 1: with GUI (Better for visulizing behavior) ####
1. Clone the whole repositry
2. In V-REP: `File -> Open scene -> choose _LAS_Gym/LAS-Scenes/livingArchitecture_ROM_exhibit.ttt_ `
   * Notes:In this manner, you can visualize the interactions among LAS, Env and Visitor. However, this visualization will slow down interaction dramatically due to vision render. We recommend you only use this method when you examine your agents' behavior. For other cases, please use **Method 2**. 

#### Method 2: without any GUI (Faster) ####
   1. Clone the whole repositry
   2. Open `Terminal` or `Command Prompt`
   3. Change directory to your vrep.exe. For example: `cd C:\Program Files\V-REP3\V-REP_PRO_EDU\`
   4. start V-REP via the command line: `vrep -h -s C:\LAS_Gym\LAS-Scenes\livingArchitecture_singleVisitor_nondistributed.ttt`

Notes:
  
  * For details on starting V-REP via the command line, please visit [here](http://www.coppeliarobotics.com/helpFiles/en/commandLine.htm).
  * You can also add path of vrep.exe to environment variable. If there is error to load scene, please firmly follow **Method 2**.
  * Compared with **Method 1**, **Method 2** is faster. Therefore, this method is preferred when you training your learning algorithm.

